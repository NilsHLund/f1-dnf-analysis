{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93eccda",
   "metadata": {},
   "source": [
    "# **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cf5a0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ed43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model selection & evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Preprocessing & pipelines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7719395",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading\n",
    "\n",
    "In this section, we:\n",
    "\n",
    "- Define a few global **configuration variables** (e.g., `RANDOM_STATE`, `TEST_SIZE`) to keep experiments consistent across models.\n",
    "- **Load** the pre-cleaned F1 dataset from disk.\n",
    "- Do a quick **sanity check** of the data shape and the target distribution for `target_finish` (DNF vs finished)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8141854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 37)\n",
      "\n",
      "Columns:\n",
      " ['year', 'round', 'grid', 'alt', 'target_finish', 'constructorRef_brabham', 'constructorRef_ferrari', 'constructorRef_ligier', 'constructorRef_mclaren', 'constructorRef_red_bull', 'constructorRef_renault', 'constructorRef_sauber', 'constructorRef_team_lotus', 'constructorRef_tyrrell', 'constructorRef_williams', 'circuitRef_hockenheimring', 'circuitRef_hungaroring', 'circuitRef_interlagos', 'circuitRef_monaco', 'circuitRef_monza', 'circuitRef_nurburgring', 'circuitRef_red_bull_ring', 'circuitRef_silverstone', 'circuitRef_spa', 'circuitRef_villeneuve', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'target_dnf']\n",
      "\n",
      "Target distribution (counts):\n",
      "target_finish\n",
      "0    7105\n",
      "1    2895\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (proportions):\n",
      "target_finish\n",
      "0    0.7105\n",
      "1    0.2895\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"processed_data.csv\"\n",
    "\n",
    "# Helper function to print evaluation metrics\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Accuracy : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall   : {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1       : {f1_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nTarget distribution (counts):\")\n",
    "print(df[\"target_finish\"].value_counts())\n",
    "\n",
    "print(\"\\nTarget distribution (proportions):\")\n",
    "print(df[\"target_finish\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c232f",
   "metadata": {},
   "source": [
    "## Train/Test Split (Time-based, aligned with main pipeline)\n",
    "\n",
    "We follow the global preprocessing pipeline and split the data by year:\n",
    "\n",
    "- **Train set**: races up to and including 2015  \n",
    "- **Test set**: races after 2015  \n",
    "\n",
    "The feature matrix `X` excludes both `target_finish` and `target_dnf`, and the\n",
    "label vector `y` uses `target_dnf` (1 = DNF, 0 = finish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44e7bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (X, y): (8550, 35) , 8550\n",
      "Test size (X, y): (1450, 35) , 1450\n",
      "\n",
      "Checking that targets are not in X columns:\n",
      "target_finish in X_train? False\n",
      "target_dnf in X_train? False\n"
     ]
    }
   ],
   "source": [
    "## Train/Test Split (Time-based, aligned with main pipeline)\n",
    "\n",
    "cutoff_year = 2015\n",
    "\n",
    "# Use the loaded processed dataframe (df) instead of encoded_data\n",
    "train_data = df[df[\"year\"] <= cutoff_year].copy()\n",
    "test_data  = df[df[\"year\"] >  cutoff_year].copy()\n",
    "\n",
    "# Feature matrix X excludes both target columns\n",
    "X_train = train_data.drop(columns=[\"target_finish\", \"target_dnf\"])\n",
    "y_train = train_data[\"target_dnf\"]\n",
    "\n",
    "X_test  = test_data.drop(columns=[\"target_finish\", \"target_dnf\"])\n",
    "y_test  = test_data[\"target_dnf\"]\n",
    "\n",
    "print(\"Training size (X, y):\", X_train.shape, \",\", len(y_train))\n",
    "print(\"Test size (X, y):\", X_test.shape, \",\", len(y_test))\n",
    "\n",
    "print(\"\\nChecking that targets are not in X columns:\")\n",
    "for col in [\"target_finish\", \"target_dnf\"]:\n",
    "    print(f\"{col} in X_train? {col in X_train.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d221bd",
   "metadata": {},
   "source": [
    "## SVM Baseline Model\n",
    "\n",
    "We start with a simple Support Vector Machine classifier using:\n",
    "- `StandardScaler` for feature normalization\n",
    "- default `SVC` settings\n",
    "\n",
    "\n",
    "We evaluate performance using Accuracy, Precision, Recall, and F1 (with DNF = 1 as the positive class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ae36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline SVM (DNF = 1) ===\n",
      "Accuracy : 0.6303\n",
      "Precision: 0.5785\n",
      "Recall   : 0.7585\n",
      "F1       : 0.6564\n"
     ]
    }
   ],
   "source": [
    "# Baseline SVM pipeline: StandardScaler + default SVC\n",
    "svm_baseline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVC(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "svm_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set\n",
    "y_pred_baseline = svm_baseline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(\"Baseline SVM (DNF = 1)\", y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84ab8f",
   "metadata": {},
   "source": [
    "## SVM Hyperparameter Search (Grid Search)\n",
    "\n",
    "In this section, we perform a hyperparameter search for the SVM model using `GridSearchCV`.\n",
    "\n",
    "We vary:\n",
    "- `kernel` (linear, rbf, poly)\n",
    "- `C` (regularization strength)\n",
    "- `gamma` (kernel coefficient for rbf and poly)\n",
    "- optionally `class_weight` (to account for class imbalance)\n",
    "\n",
    "We use 5-fold cross-validation on the training data and optimize for **F1 score** with DNF = 1 as the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params from grid search:\n",
      "{'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'rbf'}\n",
      "Best CV F1: 0.8711\n"
     ]
    }
   ],
   "source": [
    "# Define SVM pipeline\n",
    "svm_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVC(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"model__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"model__C\": [0.1, 1, 10],\n",
    "    \"model__gamma\": [\"scale\", 0.1, 0.01],  # gamma used for rbf/poly\n",
    "}\n",
    "\n",
    "# Grid search object\n",
    "svm_grid = GridSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params from grid search:\")\n",
    "print(svm_grid.best_params_)\n",
    "print(f\"Best CV F1: {svm_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79ecff",
   "metadata": {},
   "source": [
    "## Top-K SVM Models: Test Set Performance\n",
    "\n",
    "Instead of only looking at the single best SVM model, we also inspect the\n",
    "top **K** hyperparameter configurations from the grid search.\n",
    "\n",
    "For each of the top-K models (ranked by mean CV F1 score), we:\n",
    "- refit the model on the full training set\n",
    "- evaluate it on the test set\n",
    "- report Accuracy, Precision, Recall, and F1 (DNF = 1 as the positive class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e33dbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>params</th>\n",
       "      <th>cv_mean_f1</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dummy(most_frequent)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'rbf'}</td>\n",
       "      <td>0.871087</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.631724</td>\n",
       "      <td>0.585248</td>\n",
       "      <td>0.717037</td>\n",
       "      <td>0.644474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'rbf'}</td>\n",
       "      <td>0.870956</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.639310</td>\n",
       "      <td>0.610145</td>\n",
       "      <td>0.623704</td>\n",
       "      <td>0.616850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'poly'}</td>\n",
       "      <td>0.868662</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.605517</td>\n",
       "      <td>0.555917</td>\n",
       "      <td>0.758519</td>\n",
       "      <td>0.641604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'poly'}</td>\n",
       "      <td>0.868447</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.608276</td>\n",
       "      <td>0.557465</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.646326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'rbf'}</td>\n",
       "      <td>0.868260</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>0.578531</td>\n",
       "      <td>0.758519</td>\n",
       "      <td>0.656410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'model__C': 1, 'model__gamma': 0.01, 'model__kernel': 'rbf'}</td>\n",
       "      <td>0.868021</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.628966</td>\n",
       "      <td>0.575691</td>\n",
       "      <td>0.771852</td>\n",
       "      <td>0.659494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'model__C': 0.1, 'model__gamma': 0.1, 'model__kernel': 'poly'}</td>\n",
       "      <td>0.867790</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.634483</td>\n",
       "      <td>0.588523</td>\n",
       "      <td>0.714074</td>\n",
       "      <td>0.645248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'poly'}</td>\n",
       "      <td>0.867469</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.633103</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.625879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'model__C': 1, 'model__gamma': 0.01, 'model__kernel': 'linear'}</td>\n",
       "      <td>0.866362</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.565543</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.613821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model__C': 1, 'model__gamma': 0.1, 'model__kernel': 'linear'}</td>\n",
       "      <td>0.866362</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.565543</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.613821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                                                              params  \\\n",
       "0      0                                                Dummy(most_frequent)   \n",
       "1      1      {'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'rbf'}   \n",
       "2      2   {'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'rbf'}   \n",
       "3      3   {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'poly'}   \n",
       "4      4     {'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'poly'}   \n",
       "5      5    {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'rbf'}   \n",
       "6      6       {'model__C': 1, 'model__gamma': 0.01, 'model__kernel': 'rbf'}   \n",
       "7      7     {'model__C': 0.1, 'model__gamma': 0.1, 'model__kernel': 'poly'}   \n",
       "8      8  {'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'poly'}   \n",
       "9      9    {'model__C': 1, 'model__gamma': 0.01, 'model__kernel': 'linear'}   \n",
       "10    10     {'model__C': 1, 'model__gamma': 0.1, 'model__kernel': 'linear'}   \n",
       "\n",
       "    cv_mean_f1  cv_std_f1  test_accuracy  test_precision  test_recall  \\\n",
       "0          NaN        NaN       0.465517        0.465517     1.000000   \n",
       "1     0.871087   0.005852       0.631724        0.585248     0.717037   \n",
       "2     0.870956   0.004408       0.639310        0.610145     0.623704   \n",
       "3     0.868662   0.005802       0.605517        0.555917     0.758519   \n",
       "4     0.868447   0.003263       0.608276        0.557465     0.768889   \n",
       "5     0.868260   0.005652       0.630345        0.578531     0.758519   \n",
       "6     0.868021   0.004663       0.628966        0.575691     0.771852   \n",
       "7     0.867790   0.003505       0.634483        0.588523     0.714074   \n",
       "8     0.867469   0.003387       0.633103        0.595716     0.659259   \n",
       "9     0.866362   0.003448       0.606897        0.565543     0.671111   \n",
       "10    0.866362   0.003448       0.606897        0.565543     0.671111   \n",
       "\n",
       "     test_f1  \n",
       "0   0.635294  \n",
       "1   0.644474  \n",
       "2   0.616850  \n",
       "3   0.641604  \n",
       "4   0.646326  \n",
       "5   0.656410  \n",
       "6   0.659494  \n",
       "7   0.645248  \n",
       "8   0.625879  \n",
       "9   0.613821  \n",
       "10  0.613821  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOP_K = 10  # number of top SVM models you want to inspect\n",
    "\n",
    "# Extract and sort by mean_test_score (which corresponds to CV F1 because scoring=\"f1\")\n",
    "cv_results = pd.DataFrame(svm_grid.cv_results_)\n",
    "cv_results_sorted = cv_results.sort_values(\n",
    "    by=\"mean_test_score\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "top_k_rows = cv_results_sorted.head(TOP_K)\n",
    "\n",
    "records = []\n",
    "\n",
    "# ==== 1) Add Dummy Baseline as Rank 0 ====\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "records.append({\n",
    "    \"rank\": 0,\n",
    "    \"params\": \"Dummy(most_frequent)\",\n",
    "    \"cv_mean_f1\": None,\n",
    "    \"cv_std_f1\": None,\n",
    "    \"test_accuracy\": accuracy_score(y_test, y_dummy),\n",
    "    \"test_precision\": precision_score(y_test, y_dummy, zero_division=0),\n",
    "    \"test_recall\": recall_score(y_test, y_dummy, zero_division=0),\n",
    "    \"test_f1\": f1_score(y_test, y_dummy, zero_division=0),\n",
    "})\n",
    "\n",
    "# ==== 2) Add Top-K SVM Models ====\n",
    "\n",
    "for idx, row in top_k_rows.iterrows():\n",
    "    params = row[\"params\"]\n",
    "\n",
    "    # Clone base pipeline and set hyperparameters\n",
    "    model = clone(svm_grid.estimator)\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # Fit on full training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rec = {\n",
    "        \"rank\": idx + 1,\n",
    "        \"params\": params,\n",
    "        \"cv_mean_f1\": row[\"mean_test_score\"],\n",
    "        \"cv_std_f1\": row[\"std_test_score\"],\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"test_precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"test_recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"test_f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    records.append(rec)\n",
    "\n",
    "# Convert to DataFrame\n",
    "comparison_df = pd.DataFrame(records)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f82b39",
   "metadata": {},
   "source": [
    "## SVM Feature Subset Experiments\n",
    "Using the best SVM hyperparameters found by the grid search (`kernel`, `C`, and `gamma`),  \n",
    "we investigate how performance changes when we restrict the model to fewer input features.\n",
    "\n",
    "We compute the absolute Pearson correlation between each **numeric** feature and the target\n",
    "   label `target_dnf`.\n",
    "We define four feature sets:\n",
    "   - **all_features** – all columns used in the original SVM\n",
    "   - **top_15_corr** – the 15 most correlated features with `target_dnf`\n",
    "   - **top_10_corr** – the 10 most correlated features\n",
    "   - **top_5_corr**  – the 5 most correlated features\n",
    "\n",
    "For each feature set we:\n",
    "   - train the same “best” SVM (same kernel, `C`, and `gamma`),\n",
    "   - evaluate Accuracy, Precision, Recall, and F1 on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM params: {'model__C': 10, 'model__gamma': 0.01, 'model__kernel': 'rbf'}\n",
      "\n",
      "Top 15 features by |correlation with target_dnf|:\n",
      "grid                       0.344964\n",
      "year                       0.276936\n",
      "constructorRef_ferrari     0.183788\n",
      "constructorRef_red_bull    0.179034\n",
      "constructorRef_mclaren     0.145330\n",
      "round                      0.123115\n",
      "constructorRef_williams    0.107466\n",
      "constructorRef_ligier      0.076682\n",
      "month_11                   0.059469\n",
      "constructorRef_tyrrell     0.050984\n",
      "constructorRef_brabham     0.049485\n",
      "month_5                    0.047390\n",
      "circuitRef_monaco          0.044537\n",
      "circuitRef_spa             0.043378\n",
      "alt                        0.043222\n",
      "Name: target_dnf, dtype: float64\n",
      "\n",
      "=== Training best SVM on all_features (35 features) ===\n",
      "\n",
      "=== Training best SVM on top_15_corr (15 features) ===\n",
      "\n",
      "=== Training best SVM on top_10_corr (10 features) ===\n",
      "\n",
      "=== Training best SVM on top_5_corr (5 features) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>n_features</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_features</td>\n",
       "      <td>35</td>\n",
       "      <td>0.631724</td>\n",
       "      <td>0.585248</td>\n",
       "      <td>0.717037</td>\n",
       "      <td>0.644474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top_15_corr</td>\n",
       "      <td>15</td>\n",
       "      <td>0.626207</td>\n",
       "      <td>0.566969</td>\n",
       "      <td>0.834074</td>\n",
       "      <td>0.675060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_10_corr</td>\n",
       "      <td>10</td>\n",
       "      <td>0.626207</td>\n",
       "      <td>0.567104</td>\n",
       "      <td>0.832593</td>\n",
       "      <td>0.674670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_5_corr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.624138</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.678466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  n_features  test_accuracy  test_precision  test_recall  \\\n",
       "0  all_features          35       0.631724        0.585248     0.717037   \n",
       "1   top_15_corr          15       0.626207        0.566969     0.834074   \n",
       "2   top_10_corr          10       0.626207        0.567104     0.832593   \n",
       "3    top_5_corr           5       0.624138        0.563725     0.851852   \n",
       "\n",
       "    test_f1  \n",
       "0  0.644474  \n",
       "1  0.675060  \n",
       "2  0.674670  \n",
       "3  0.678466  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the best hyperparameters from the grid search\n",
    "best_params = svm_grid.best_params_\n",
    "print(\"Best SVM params:\", best_params)\n",
    "\n",
    "# Compute correlations with the target for numeric features\n",
    "corr = df.corr(numeric_only=True)[\"target_dnf\"].abs().sort_values(ascending=False)\n",
    "\n",
    "# Drop the target itself\n",
    "corr = corr.drop(labels=[\"target_dnf\", \"target_finish\"], errors=\"ignore\")\n",
    "\n",
    "print(\"\\nTop 15 features by |correlation with target_dnf|:\")\n",
    "print(corr.head(15))\n",
    "\n",
    "# Define different feature subsets\n",
    "feature_sets = {\n",
    "    \"all_features\": X_train.columns.tolist(),\n",
    "    \"top_15_corr\": corr.head(15).index.tolist(),\n",
    "    \"top_10_corr\": corr.head(10).index.tolist(),\n",
    "    \"top_5_corr\":  corr.head(5).index.tolist(),\n",
    "}\n",
    "\n",
    "# Train the same best SVM on each subset and evaluate\n",
    "feature_records = []\n",
    "\n",
    "for name, cols in feature_sets.items():\n",
    "    print(f\"\\n=== Training best SVM on {name} ({len(cols)} features) ===\")\n",
    "    \n",
    "    X_train_sub = X_train[cols]\n",
    "    X_test_sub  = X_test[cols]\n",
    "    \n",
    "    svm_best = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", SVC(random_state=RANDOM_STATE)),\n",
    "    ])\n",
    "    svm_best.set_params(**best_params)\n",
    "    \n",
    "    svm_best.fit(X_train_sub, y_train)\n",
    "    y_pred_sub = svm_best.predict(X_test_sub)\n",
    "    \n",
    "    feature_records.append({\n",
    "        \"features\": name,\n",
    "        \"n_features\": len(cols),\n",
    "        \"test_accuracy\":  accuracy_score(y_test, y_pred_sub),\n",
    "        \"test_precision\": precision_score(y_test, y_pred_sub, zero_division=0),\n",
    "        \"test_recall\":    recall_score(y_test, y_pred_sub, zero_division=0),\n",
    "        \"test_f1\":        f1_score(y_test, y_pred_sub, zero_division=0),\n",
    "    })\n",
    "\n",
    "feature_results_df = pd.DataFrame(feature_records)\n",
    "display(feature_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bffc6d6",
   "metadata": {},
   "source": [
    "## Uncertainty via Distance to the Decision Boundary\n",
    "We take the best SVM pipeline from the grid search and compute\n",
    "  `decision_function(X_test)`, which returns a signed score proportional to the distance\n",
    "  of each test example from the decision boundary.\n",
    "- We look at the **absolute value** of these scores (the margin) and summarize them by:\n",
    "  - median |margin|,\n",
    "  - 10th percentile |margin| (examples close to the boundary, more uncertain),\n",
    "  - 90th percentile |margin| (examples far from the boundary, more confident)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49469938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples: 1450\n",
      "Median |margin|          : 0.7052\n",
      "10th percentile |margin| : 0.1773\n",
      "90th percentile |margin| : 1.6067\n"
     ]
    }
   ],
   "source": [
    "# Best full pipeline from grid search (includes scaler + SVC)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# decision_function gives signed distance-like scores to the decision boundary\n",
    "decision_scores = best_svm.decision_function(X_test)\n",
    "abs_scores = np.abs(decision_scores)\n",
    "\n",
    "print(\"Number of test examples:\", len(abs_scores))\n",
    "print(f\"Median |margin|          : {np.median(abs_scores):.4f}\")\n",
    "print(f\"10th percentile |margin| : {np.percentile(abs_scores, 10):.4f}\")\n",
    "print(f\"90th percentile |margin| : {np.percentile(abs_scores, 90):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
