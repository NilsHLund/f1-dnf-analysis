{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b22f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbaecbf",
   "metadata": {},
   "source": [
    "### Loading data and prining out head & shape ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed50103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   resultId  raceId  year  round  grid  positionOrder  points  laps milliseconds fastestLap rank fastestLapTime fastestLapSpeed        driverRef     surname forename         dob nationality_x constructorRef                          name nationality_y     circuitRef  circuitId        name_y    location  country      lat        lng  alt        date  target_finish\n",
      "0      2460     136  2002     13    11              4     3.0  77.0          NaN         \\N   \\N             \\N              \\N        raikkonen   Räikkönen     Kimi  1979-10-17       Finnish        mclaren                   Hungaroring       British    hungaroring         11       McLaren    Budapest  Hungary  47.5789   19.24860  264  2002-08-18              1\n",
      "1     11565     483  1981      1    23             21     0.0  16.0           \\N         \\N   \\N             \\N              \\N           watson      Watson     John  1946-05-04       British        mclaren                    Long Beach       British     long_beach         43       McLaren  California      USA  33.7651 -118.18900   12  1981-03-15              0\n",
      "2     18661     772  1958      8     0             26     0.0   0.0           \\N         \\N   \\N             \\N              \\N          ruttman     Ruttman     Troy  1930-03-11      American       maserati                   Nürburgring       Italian    nurburgring         20      Maserati     Nürburg  Germany  50.3356    6.94750  578  1958-08-03              0\n",
      "3     25121    1058  2021      8    19             16     0.0  69.0           \\N         57   16       1:10.005         222.052  mick_schumacher  Schumacher     Mick  1999-03-22        German           haas                 Red Bull Ring      American  red_bull_ring         70  Haas F1 Team   Spielberg  Austria  47.2197   14.76470  678  2021-06-27              0\n",
      "4      8863     383  1988     12     0             30     0.0   0.0           \\N         \\N   \\N             \\N              \\N           modena      Modena  Stefano  1963-05-12       Italian       eurobrun  Autodromo Nazionale di Monza       Italian          monza         14     Euro Brun       Monza    Italy  45.6156    9.28111  162  1988-09-11              0\n",
      "Shape:  (10000, 31)\n"
     ]
    }
   ],
   "source": [
    "#Importing data to dataframe\n",
    "raw_data = pd.read_csv('data.csv')\n",
    "print(raw_data.head().to_string())\n",
    "print(\"Shape: \", raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e084133",
   "metadata": {},
   "source": [
    "### Print overview of columns containing NA values, and dropping using 90% threshold ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae258767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NA and NA count: \n",
      "points              971\n",
      "laps                978\n",
      "milliseconds       7393\n",
      "fastestLap         6895\n",
      "rank               6798\n",
      "fastestLapTime     6895\n",
      "fastestLapSpeed    7191\n",
      "dtype: int64\n",
      "\n",
      "Shape with 90% threshold for dropping column:\n",
      "(10000, 26)\n",
      "Index(['resultId', 'raceId', 'year', 'round', 'grid', 'positionOrder',\n",
      "       'points', 'laps', 'driverRef', 'surname', 'forename', 'dob',\n",
      "       'nationality_x', 'constructorRef', 'name', 'nationality_y',\n",
      "       'circuitRef', 'circuitId', 'name_y', 'location', 'country', 'lat',\n",
      "       'lng', 'alt', 'date', 'target_finish'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Make sure other types of missing data is also registered as missing data\n",
    "missing_markers = ['\\\\N', 'NULL', 'null', ''] \n",
    "raw_data = raw_data.replace(missing_markers, np.nan)\n",
    "\n",
    "nullValues = raw_data.isnull().sum()\n",
    "print(\"Rows with NA and NA count: \")\n",
    "print(nullValues[nullValues > 0])\n",
    "print(\"\\nShape with 90% threshold for dropping column:\")\n",
    "thresh = round(0.9*raw_data.shape[0])\n",
    "trimmed_raw_data = raw_data.dropna(axis=1, thresh=thresh)\n",
    "print(trimmed_raw_data.shape)\n",
    "print(trimmed_raw_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e69c7c",
   "metadata": {},
   "source": [
    "### Further feature selection ###\n",
    "Some columns have leakage features, meaning they have a 1-1 correlation with what we try to predict.These need to be removed as they will make the predictions too \"easy\". Some of these are also measurements made after after the target value is measured, and therefore don't have any predictive power. E.g. \"positionOrder\" and \"points\", which are based upon whether the driver finishes the race or not. <br>\n",
    "Will keep features 'year', 'round', 'grid', 'constructorRef', 'circuitRef', 'alt', 'date' as well as 'target_finish' <br>\n",
    "Reasons one by one: <br><br>\n",
    "\n",
    "##### Id's #####\n",
    "- resultId: DROP – not useful\n",
    "\n",
    "- raceId: DROP – not useful\n",
    "\n",
    "- circuitId: DROP – Redundant with circuitRef\n",
    "\n",
    "##### Race metadata #####\n",
    "\n",
    "- year: KEEP – DNF rates may vary over the years\n",
    "\n",
    "- round: KEEP – Early/late season influences DNF\n",
    "\n",
    "- date: KEEP – Weather/season patterns\n",
    "\n",
    "- country: DROP - redundant with circuitRef\n",
    "\n",
    "##### Driver & team #####\n",
    "\n",
    "- driverRef: DROP - High cardinality, too sparse. Data of retired drivers unuseful for future drivers\n",
    "\n",
    "- surname: DROP – same reason as driverRef\n",
    "\n",
    "- forename: DROP – same reason as driverRef\n",
    "\n",
    "- dob: DROP – weak predictor\n",
    "\n",
    "- nationality_x: DROP – Weak predictor\n",
    "\n",
    "- constructorRef: KEEP – Team strongly impacts DNF\n",
    "\n",
    "- nationality_y: DROP – irrelevant / redundant to constructorRef\n",
    "\n",
    "##### Performance stats #####\n",
    "\n",
    "- grid: KEEP – Starting position affects crash risk\n",
    "\n",
    "- positionOrder: DROP – Leakage (reveals final result)\n",
    "\n",
    "##### Circuit info #####\n",
    "\n",
    "- circuitRef: KEEP – Tracks differ in DNF probability\n",
    "\n",
    "- name: DROP – Duplicate of circuitRef\n",
    "\n",
    "- name_y: DROP – Another duplicate\n",
    "\n",
    "- location: DROP – Text field, not useful\n",
    "\n",
    "##### Geographical #####\n",
    "\n",
    "- lat: DROP – Raw coordinate not meaningful\n",
    "\n",
    "- lng: DROP – Same as above\n",
    "\n",
    "- alt: KEEP - altitude of tracks may be predicitive  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ca9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 8)\n",
      "Features: Index(['year', 'round', 'grid', 'constructorRef', 'circuitRef', 'alt', 'date',\n",
      "       'target_finish'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [\n",
    "    'year', 'round', 'grid', 'constructorRef',\n",
    "    'circuitRef', 'alt', 'date',\n",
    "    'target_finish'\n",
    "]\n",
    "clean_data = trimmed_raw_data[keep_cols]\n",
    "print(\"Shape:\", clean_data.shape)\n",
    "print(\"Features:\",clean_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08499e",
   "metadata": {},
   "source": [
    "### Dropping rows with NA values (redundant as columns containing NA are removed already) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd36e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping rows with NA values and columns with >90% NA values:\n",
      " (10000, 8)\n"
     ]
    }
   ],
   "source": [
    "clean_data = clean_data.dropna()\n",
    "print(\"Shape after dropping rows with NA values and columns with >90% NA values:\\n\",clean_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66ef68",
   "metadata": {},
   "source": [
    "### Printing out describtion of dataframe, and ranked correlation between numerical features for analysis ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13904c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               year         round          grid           alt  target_finish\n",
      "count  10000.000000  10000.000000  10000.000000  10000.000000   10000.000000\n",
      "mean    1991.466600      8.540100     11.176200    281.465900       0.289500\n",
      "std       20.060237      5.085487      7.241008    414.586363       0.453553\n",
      "min     1950.000000      1.000000      0.000000     -7.000000       0.000000\n",
      "25%     1977.000000      4.000000      5.000000     18.000000       0.000000\n",
      "50%     1991.000000      8.000000     11.000000    153.000000       0.000000\n",
      "75%     2009.000000     12.000000     17.000000    401.000000       1.000000\n",
      "max     2024.000000     24.000000     34.000000   2227.000000       1.000000\n",
      "\n",
      "Correlation between numerical features and target_finish ranked on abs value\n",
      "grid    -0.344964\n",
      "year     0.276936\n",
      "round    0.123115\n",
      "alt     -0.043222\n",
      "Name: target_finish, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.describe().to_string())\n",
    "print(\"\\nCorrelation between numerical features and target_finish ranked on abs value\")\n",
    "print(clean_data.corr(numeric_only=True)['target_finish'].sort_values(key=abs, ascending=False)[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f88172",
   "metadata": {},
   "source": [
    "### Handling 'object' values ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a0eef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90fcc5f6",
   "metadata": {},
   "source": [
    "Will use a reduced One Hot Encoding. Let the top 10 most common values per feature be one hot encoded, place all other values under a group called 'other...'\n",
    "\n",
    "Then convert date to month, and OHE it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b97271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[\"date\"] = pd.to_datetime(clean_data[\"date\"]).dt.month\n",
    "clean_data = clean_data.rename(columns={\"date\":\"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953ed0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 constructorRefs are: ['ferrari', 'mclaren', 'williams', 'sauber', 'team_lotus', 'tyrrell', 'red_bull', 'renault', 'ligier', 'brabham']\n"
     ]
    }
   ],
   "source": [
    "top_10_constructorRefs = clean_data['constructorRef'].value_counts().nlargest(10).index\n",
    "\n",
    "print(\"The Top 10 constructorRefs are:\", list(top_10_constructorRefs))\n",
    "\n",
    "# Replace country if not in top 10 with 'Other'\n",
    "clean_data['constructorRef'] = clean_data['constructorRef'].apply(\n",
    "    lambda x: x if x in top_10_constructorRefs else 'other_const'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a0e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 circuitRef are: ['monza', 'monaco', 'silverstone', 'spa', 'villeneuve', 'hungaroring', 'nurburgring', 'hockenheimring', 'interlagos', 'red_bull_ring']\n"
     ]
    }
   ],
   "source": [
    "top_10_circuitRef = clean_data['circuitRef'].value_counts().nlargest(10).index\n",
    "\n",
    "print(\"The Top 10 circuitRef are:\", list(top_10_circuitRef))\n",
    "\n",
    "# Replace country if not in top 10 with 'Other'\n",
    "clean_data['circuitRef'] = clean_data['circuitRef'].apply(\n",
    "    lambda x: x if x in top_10_circuitRef else 'other_circ'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390fbbe",
   "metadata": {},
   "source": [
    "### Dataset before OHE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a92f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  round  grid constructorRef     circuitRef  alt  month  target_finish\n",
      "0  2002     13    11        mclaren    hungaroring  264      8              1\n",
      "1  1981      1    23        mclaren     other_circ   12      3              0\n",
      "2  1958      8     0    other_const    nurburgring  578      8              0\n",
      "3  2021      8    19    other_const  red_bull_ring  678      6              0\n",
      "4  1988     12     0    other_const          monza  162      9              0\n"
     ]
    }
   ],
   "source": [
    "print(clean_data.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63235928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat = [\"constructorRef\", \"circuitRef\", \"month\"]\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(clean_data[cat])\n",
    "cat_data = enc.transform(clean_data[cat]).toarray()\n",
    "\n",
    "cat_df = pd.DataFrame(data = cat_data, columns = enc.get_feature_names_out(), index = clean_data.index)\n",
    "encoded_data = clean_data.join(cat_df).drop(columns = cat)\n",
    "\n",
    "# Dropped to avoid linear dependencies \n",
    "encoded_data = encoded_data.drop(columns=[\"circuitRef_other_circ\", \"constructorRef_other_const\", \"month_12\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60a3d3",
   "metadata": {},
   "source": [
    "### Dataset after OHE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c457a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  round  grid  alt  target_finish  constructorRef_brabham  constructorRef_ferrari  constructorRef_ligier  constructorRef_mclaren  constructorRef_red_bull  constructorRef_renault  constructorRef_sauber  constructorRef_team_lotus  constructorRef_tyrrell  constructorRef_williams  circuitRef_hockenheimring  circuitRef_hungaroring  circuitRef_interlagos  circuitRef_monaco  circuitRef_monza  circuitRef_nurburgring  circuitRef_red_bull_ring  circuitRef_silverstone  circuitRef_spa  circuitRef_villeneuve  month_1  month_2  month_3  month_4  month_5  month_6  month_7  month_8  month_9  month_10  month_11\n",
      "0  2002     13    11  264              1                     0.0                     0.0                    0.0                     1.0                      0.0                     0.0                    0.0                        0.0                     0.0                      0.0                        0.0                     1.0                    0.0                0.0               0.0                     0.0                       0.0                     0.0             0.0                    0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0       0.0       0.0\n",
      "1  1981      1    23   12              0                     0.0                     0.0                    0.0                     1.0                      0.0                     0.0                    0.0                        0.0                     0.0                      0.0                        0.0                     0.0                    0.0                0.0               0.0                     0.0                       0.0                     0.0             0.0                    0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0\n",
      "2  1958      8     0  578              0                     0.0                     0.0                    0.0                     0.0                      0.0                     0.0                    0.0                        0.0                     0.0                      0.0                        0.0                     0.0                    0.0                0.0               0.0                     1.0                       0.0                     0.0             0.0                    0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0       0.0       0.0\n",
      "3  2021      8    19  678              0                     0.0                     0.0                    0.0                     0.0                      0.0                     0.0                    0.0                        0.0                     0.0                      0.0                        0.0                     0.0                    0.0                0.0               0.0                     0.0                       1.0                     0.0             0.0                    0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0       0.0       0.0\n",
      "4  1988     12     0  162              0                     0.0                     0.0                    0.0                     0.0                      0.0                     0.0                    0.0                        0.0                     0.0                      0.0                        0.0                     0.0                    0.0                0.0               1.0                     0.0                       0.0                     0.0             0.0                    0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0       0.0       0.0\n",
      "(10000, 36)\n",
      "Index(['year', 'round', 'grid', 'alt', 'target_finish',\n",
      "       'constructorRef_brabham', 'constructorRef_ferrari',\n",
      "       'constructorRef_ligier', 'constructorRef_mclaren',\n",
      "       'constructorRef_red_bull', 'constructorRef_renault',\n",
      "       'constructorRef_sauber', 'constructorRef_team_lotus',\n",
      "       'constructorRef_tyrrell', 'constructorRef_williams',\n",
      "       'circuitRef_hockenheimring', 'circuitRef_hungaroring',\n",
      "       'circuitRef_interlagos', 'circuitRef_monaco', 'circuitRef_monza',\n",
      "       'circuitRef_nurburgring', 'circuitRef_red_bull_ring',\n",
      "       'circuitRef_silverstone', 'circuitRef_spa', 'circuitRef_villeneuve',\n",
      "       'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n",
      "       'month_7', 'month_8', 'month_9', 'month_10', 'month_11'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data.head().to_string())\n",
    "print(encoded_data.shape)\n",
    "print(encoded_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2c6dd",
   "metadata": {},
   "source": [
    "## Flip values in target_finish ## \n",
    "We want to detect DNF, make this our positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb5caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_dnf\n",
      "1    7105\n",
      "0    2895\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "encoded_data['target_dnf'] = 1 - encoded_data['target_finish']\n",
    "encoded_data = encoded_data.drop(columns=[\"target_finish\"])\n",
    "print(encoded_data[\"target_dnf\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb64f85",
   "metadata": {},
   "source": [
    "## Data split ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75442909",
   "metadata": {},
   "source": [
    "cutoff_year set to 2015 arbitrarily for now. Can change this, but gives a reasonable split (test size ~15% of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459378a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (X, y): (8550, 35) , 8550\n",
      "Test size (X, y): (1450, 35) , 1450\n"
     ]
    }
   ],
   "source": [
    "cutoff_year = 2015\n",
    "\n",
    "train_data = encoded_data[encoded_data['year'] <= cutoff_year].copy()\n",
    "test_data  = encoded_data[encoded_data['year'] >  cutoff_year].copy()\n",
    "\n",
    "X_train = train_data.drop(columns=['target_dnf'])\n",
    "y_train = train_data['target_dnf']\n",
    "\n",
    "X_test  = test_data.drop(columns=['target_dnf'])\n",
    "y_test  = test_data['target_dnf']\n",
    "\n",
    "print(\"Training size (X, y):\", X_train.shape, \",\", len(y_train))\n",
    "print(\"Test size (X, y):\", X_test.shape, \",\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4537a",
   "metadata": {},
   "source": [
    "Beginning of logistic regression\n",
    "Starting with finding strong features using Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50818851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random_seed = 2334\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "feature_extractor = LogisticRegression(penalty='l1', solver='liblinear', random_state=random_seed, C=1)\n",
    "\n",
    "feature_extractor.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Threshold 0.05, this gives 19 features with C=1\n",
    "thresh = 0.05\n",
    "\n",
    "significant = X_train.columns[abs(feature_extractor.coef_[0])>thresh]\n",
    "coefficients = feature_extractor.coef_[0][abs(feature_extractor.coef_[0])>thresh]\n",
    "z = list(zip(significant, coefficients))\n",
    "z.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "significantSorted = [p[0] for p in z]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f968d",
   "metadata": {},
   "source": [
    "After Lasso has had its way with our features, we are left with 19\n",
    "We will then test out different subsets of these in conjunction with changing the levels of regularization\n",
    "To do this we will create a pipeline and use a Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfdbe28",
   "metadata": {},
   "source": [
    "What happens in the following cell\n",
    "1. We define a list of lists of features. These are selected based on the output of the previous cell, where lasso assigns higher coefficients to features with more predictive power. I try all, then only the significant ones, the 7 best, the best half, best quarter, worst half and then in the end constructors and circuits for fun (might remove these)\n",
    "2. I define a parametergrid, currently the only parameter is C, which is the amount of lasso-regularization. \n",
    "3. I iterate through the different subsets of features, and do gridsearch, with a cv of 5, for each one of them. \n",
    "4. We save the best result of each feature-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26174217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid', 'year', 'constructorRef_ferrari', 'constructorRef_mclaren', 'constructorRef_williams', 'circuitRef_nurburgring', 'constructorRef_red_bull', 'circuitRef_monaco', 'constructorRef_ligier', 'month_10', 'constructorRef_renault', 'constructorRef_team_lotus', 'circuitRef_spa', 'circuitRef_interlagos', 'alt', 'constructorRef_tyrrell', 'month_3', 'circuitRef_silverstone', 'circuitRef_villeneuve']\n",
      "**Feature_Set_1_(35 columns)**: Best Score = 0.8022, Best C = 0.0464\n",
      "**Feature_Set_2_(19 columns)**: Best Score = 0.8016, Best C = 0.0464\n",
      "**Feature_Set_3_(7 columns)**: Best Score = 0.8012, Best C = 0.0464\n",
      "**Feature_Set_4_(9 columns)**: Best Score = 0.8006, Best C = 0.2154\n",
      "**Feature_Set_5_(4 columns)**: Best Score = 0.7927, Best C = 0.0464\n",
      "**Feature_Set_6_(9 columns)**: Best Score = 0.7523, Best C = 4.6416\n",
      "**Feature_Set_constructors_(10 columns)**: Best Score = 0.7588, Best C = 0.0464\n",
      "**Feature_Set_circuits_(10 columns)**: Best Score = 0.7520, Best C = 0.0100\n",
      "0.752046783625731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "print(significantSorted)\n",
    "\n",
    "#We try all the features, the best half and quarter, as well as the worst half for fun\n",
    "listsOfFeatures = [\n",
    "    X_train.columns,\n",
    "    significantSorted,\n",
    "    significantSorted[0:7],\n",
    "    significantSorted[0:len(significantSorted)//2],\n",
    "    significantSorted[0:len(significantSorted)//4],\n",
    "    significantSorted[len(significantSorted)//2:-1],\n",
    "    [s for s in X_train.columns if 'constructorRef' in s],\n",
    "    [s for s in X_train.columns if 'circuitRef' in s],\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'model__C' : np.logspace(-2, 2, 7),\n",
    "}\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, solver='liblinear', penalty='l1', random_state=random_seed))\n",
    "])\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i, features in enumerate(listsOfFeatures):\n",
    "    X_train_iter = X_train[features]\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "    if i == 6:\n",
    "        key = f\"Feature_Set_constructors_({len(features)} columns)\"\n",
    "    elif i == 7:\n",
    "        key = f\"Feature_Set_circuits_({len(features)} columns)\"\n",
    "    else:\n",
    "        key = f\"Feature_Set_{i+1}_({len(features)} columns)\"\n",
    "    grid.fit(X_train_iter, y_train)\n",
    "\n",
    "\n",
    "    #Storing results\n",
    "    results[key] = {\n",
    "        'best_score': grid.best_score_,\n",
    "        'best_params': grid.best_params_,\n",
    "        'features_used': features\n",
    "    }\n",
    "\n",
    "for key, res in results.items():\n",
    "    print(f\"**{key}**: Best Score = {res['best_score']:.4f}, Best C = {res['best_params']['model__C']:.4f}\")\n",
    "\n",
    "print(sum(y_train)/len(y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
